{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\n\nurl = 'https://drive.google.com/uc?id=1YQwBlGvqodie2zzurPIqZ7dswTHc6-9o'\n\noutput = 'MIDV-2020.zip'\ngdown.download(url, output)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T16:57:57.130461Z","iopub.execute_input":"2022-09-13T16:57:57.130852Z","iopub.status.idle":"2022-09-13T16:58:14.001767Z","shell.execute_reply.started":"2022-09-13T16:57:57.130801Z","shell.execute_reply":"2022-09-13T16:58:14.000756Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1YQwBlGvqodie2zzurPIqZ7dswTHc6-9o\nTo: /kaggle/working/MIDV-2020.zip\n100%|██████████| 3.98G/3.98G [00:15<00:00, 256MB/s] \n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'MIDV-2020.zip'"},"metadata":{}}]},{"cell_type":"code","source":"!unzip MIDV-2020.zip >/dev/null\nprint('[INFO] The dataset has been unzipped...')","metadata":{"execution":{"iopub.status.busy":"2022-09-13T16:58:14.007138Z","iopub.execute_input":"2022-09-13T16:58:14.009969Z","iopub.status.idle":"2022-09-13T16:58:52.438101Z","shell.execute_reply.started":"2022-09-13T16:58:14.009914Z","shell.execute_reply":"2022-09-13T16:58:52.433961Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[INFO] The dataset has been unzipped...\n","output_type":"stream"}]},{"cell_type":"code","source":"import io\nimport math\nimport os\nimport sys\nimport torch\nimport wandb\nimport albumentations as A\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sn\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import models\nfrom torchvision import datasets\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-09-13T17:02:13.532582Z","iopub.execute_input":"2022-09-13T17:02:13.533496Z","iopub.status.idle":"2022-09-13T17:02:18.485316Z","shell.execute_reply.started":"2022-09-13T17:02:13.533455Z","shell.execute_reply":"2022-09-13T17:02:18.484261Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import wandb\n\n# WandB – Log in to your wandb account so you can log all your metrics\nwandb.login()","metadata":{"execution":{"iopub.status.busy":"2022-10-06T07:18:08.271429Z","iopub.execute_input":"2022-10-06T07:18:08.271844Z","iopub.status.idle":"2022-10-06T07:18:25.781414Z","shell.execute_reply.started":"2022-10-06T07:18:08.271813Z","shell.execute_reply":"2022-10-06T07:18:25.780095Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"# Define the name of the dataset\nDATASET_NAME = 'MIDV-2020'\n\n# Define the path to train and valid dataset\nTRAIN_PATH = os.path.join(DATASET_NAME, 'train')\nVALID_PATH = os.path.join(DATASET_NAME, 'test')\n\n# Define the input image dimensions\nIMAGE_SIZE = 224\n\n# Define the labels\nLABELS = sorted(os.listdir(os.path.join(TRAIN_PATH, 'images')))","metadata":{"execution":{"iopub.status.busy":"2022-09-13T17:02:20.768230Z","iopub.execute_input":"2022-09-13T17:02:20.768610Z","iopub.status.idle":"2022-09-13T17:02:20.774203Z","shell.execute_reply.started":"2022-09-13T17:02:20.768577Z","shell.execute_reply":"2022-09-13T17:02:20.773466Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class Transforms:\n    def __init__(self):\n        self.transforms = A.Compose([\n            A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n            A.Normalize(),\n            ToTensorV2()\n        ])\n\n    def __call__(self, img, *args, **kwargs):\n        return self.transforms(image=np.array(img))['image']\n\n# Create the train and valid datasets\ntrain_dataset = datasets.ImageFolder(os.path.join(TRAIN_PATH, 'images'), transform=Transforms())\nvalid_dataset = datasets.ImageFolder(os.path.join(VALID_PATH, 'images'), transform=Transforms())\n\n# Create the train and valid data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=os.cpu_count())\nvalid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=os.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2022-09-13T17:02:21.926675Z","iopub.execute_input":"2022-09-13T17:02:21.928220Z","iopub.status.idle":"2022-09-13T17:02:21.961265Z","shell.execute_reply.started":"2022-09-13T17:02:21.928162Z","shell.execute_reply":"2022-09-13T17:02:21.953965Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Determine the device to be used for training and training\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# Initialize the pre-trained model\nmodel = models.resnet50(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, len(LABELS))\n\n# Send the model to the GPU if available\nmodel = model.to(DEVICE)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-09-13T17:02:32.738734Z","iopub.execute_input":"2022-09-13T17:02:32.739179Z","iopub.status.idle":"2022-09-13T17:02:42.664684Z","shell.execute_reply.started":"2022-09-13T17:02:32.739142Z","shell.execute_reply":"2022-09-13T17:02:42.663707Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/97.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7194e0397904adc8bfd16933abfc31f"}},"metadata":{}}]},{"cell_type":"code","source":"def format_logs(metrics):\n    logs = [\"{} - {:.4}\".format(k, v) for k, v in metrics.items()]\n    return ', '.join(logs)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T15:57:33.565839Z","iopub.execute_input":"2022-08-16T15:57:33.566206Z","iopub.status.idle":"2022-08-16T15:57:33.573460Z","shell.execute_reply.started":"2022-08-16T15:57:33.566172Z","shell.execute_reply":"2022-08-16T15:57:33.572578Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def run_epoch(epoch, data_loader, mode='train'):\n    if mode == 'train':\n        model.train()\n    else:\n        model.eval()\n    \n    y_pred = torch.zeros(0, dtype=torch.long, device='cpu')\n    y_true = torch.zeros(0, dtype=torch.long, device='cpu')\n    \n    for batch_idx, (inputs, labels) in enumerate(data_loader, 1):\n        (inputs, labels) = (inputs.to(DEVICE), labels.to(DEVICE))\n        optimizer.zero_grad()\n            \n        with torch.set_grad_enabled(mode == 'train'):\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            _, preds = torch.max(outputs, 1)\n                \n            y_pred = torch.cat([y_pred, preds.view(-1).cpu()])\n            y_true = torch.cat([y_true, labels.view(-1).cpu()])\n            \n        if mode == 'train':\n            loss.backward()\n            optimizer.step()\n            \n        metrics = {\n            'loss': loss,\n            'accuracy': accuracy_score(y_true, y_pred),\n            'precision': precision_score(y_true, y_pred, average='macro', zero_division=1),\n            'recall': recall_score(y_true, y_pred, average='macro', zero_division=1),\n            'f1_score': f1_score(y_true, y_pred, average='macro', zero_division=1)\n        }\n        \n        if batch_idx % 5 == 0:\n            print('Epoch: {} - {}: {}% ({}/{}) [{}]'.format(epoch, mode,\n                                                            int(100 * batch_idx / len(data_loader)),\n                                                            batch_idx, len(data_loader),\n                                                            format_logs(metrics)))\n    \n    matrix = confusion_matrix(y_pred, y_true)\n    report = classification_report(y_true, y_pred, target_names=LABELS)\n    report_dict = classification_report(y_true, y_pred, target_names=LABELS, output_dict=True)\n    \n    return {'matrix': matrix, 'report': report, 'report_dict': report_dict, 'metrics': metrics}","metadata":{"execution":{"iopub.status.busy":"2022-08-16T16:14:21.783541Z","iopub.execute_input":"2022-08-16T16:14:21.783988Z","iopub.status.idle":"2022-08-16T16:14:21.799056Z","shell.execute_reply.started":"2022-08-16T16:14:21.783948Z","shell.execute_reply":"2022-08-16T16:14:21.798189Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def save_matrix(matrix, file_name):\n    df_cm = pd.DataFrame(matrix, index=[i for i in LABELS], columns=[i for i in LABELS]).astype(int)\n    fig = plt.figure(figsize=(15,10))\n    ax = sn.heatmap(df_cm, annot=True)\n    ax.yaxis.set_ticklabels(ax.yaxis.get_ticklabels(), rotation=0, ha='right')\n    ax.xaxis.set_ticklabels(ax.xaxis.get_ticklabels(), rotation=45, ha='right')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.savefig(file_name, bbox_inches='tight')\n    plt.close(fig)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T15:57:41.018914Z","iopub.execute_input":"2022-08-16T15:57:41.019534Z","iopub.status.idle":"2022-08-16T15:57:41.028691Z","shell.execute_reply.started":"2022-08-16T15:57:41.019477Z","shell.execute_reply":"2022-08-16T15:57:41.027751Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_report(report):\n    data = []\n    columns = ['', 'precision', 'recall', 'f1_score', 'support']\n    for key in report:\n        if key == 'accuracy':\n            accuracy = format(report[key], '.4f')\n            support = str(report['macro avg']['support'])\n            data.append([key, '', '', accuracy, support])\n        else:\n            precision = format(report[key]['precision'], '.4f')\n            recall = format(report[key]['recall'], '.4f')\n            f1_score = format(report[key]['f1-score'], '.4f')\n            support = str(report[key]['support'])\n            data.append([key, precision, recall, f1_score, support])\n            \n    return wandb.Table(data=data, columns=columns)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T15:57:43.426835Z","iopub.execute_input":"2022-08-16T15:57:43.427189Z","iopub.status.idle":"2022-08-16T15:57:43.435305Z","shell.execute_reply.started":"2022-08-16T15:57:43.427157Z","shell.execute_reply":"2022-08-16T15:57:43.433244Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# WandB – Initialize a new run\nwandb.init(entity=\"jsun-dev\", project=\"document-classification\")\nwandb.watch(model, log=\"all\")\n\nbest_epoch = 0\nbest_loss = float('inf')\nbest_accuracy = 0.0\nbest_metrics = {}\n\n# Train the model\nfor i in range(10):\n    # Train and optimize on the training dataset\n    train_logs = run_epoch(i, train_loader, mode='train')\n    save_matrix(train_logs['matrix'], 'train_matrix.png')\n    print('\\n{}'.format(train_logs['report']))\n    train_report = train_logs['report_dict']\n    train_metrics = train_logs['metrics']\n    \n    # Evaluate on the validation dataset\n    valid_logs = run_epoch(i, valid_loader, mode='valid')\n    save_matrix(valid_logs['matrix'], 'valid_matrix.png')\n    print('\\n{}'.format(valid_logs['report']))\n    valid_report = valid_logs['report_dict']\n    valid_metrics = valid_logs['metrics']\n    \n    # Criteria for improved model\n    valid_loss = valid_metrics['loss']\n    valid_accuracy = valid_metrics['accuracy']\n    better_accuracy = (valid_accuracy > best_accuracy)\n    similar_accuracy_better_loss = (math.isclose(valid_accuracy, best_accuracy, rel_tol=1e-3)\n                                    and valid_loss < best_loss)\n    \n    # Save model if improved\n    if better_accuracy or similar_accuracy_better_loss:\n        best_epoch = i\n        best_loss = valid_loss\n        best_accuracy = valid_accuracy\n        best_metrics = valid_metrics\n        wandb.run.summary['best_epoch'] = best_epoch\n        wandb.run.summary['best_loss'] = best_metrics['loss']\n        wandb.run.summary['best_accuracy'] = best_metrics['accuracy']\n        wandb.run.summary['best_precision'] = best_metrics['precision']\n        wandb.run.summary['best_recall'] = best_metrics['recall']\n        wandb.run.summary['best_f1_score'] = best_metrics['f1_score']\n        torch.save(model.state_dict(), './best_model.pth')\n        print('Improved model saved!')\n    \n    # Log epoch results\n    wandb.log({\n        'train/loss': train_metrics['loss'],\n        'train/accuracy': train_metrics['accuracy'],\n        'train/precision': train_metrics['precision'],\n        'train/recall': train_metrics['recall'],\n        'train/f1_score': train_metrics['f1_score'],\n        'valid/loss': valid_metrics['loss'],\n        'valid/accuracy': valid_metrics['accuracy'],\n        'valid/precision': valid_metrics['precision'],\n        'valid/recall': valid_metrics['recall'],\n        'valid/f1_score': valid_metrics['f1_score'],\n        'report/train': get_report(train_report),\n        'report/valid': get_report(valid_report),\n        'matrix/train': wandb.Image('train_matrix.png'),\n        'matrix/valid': wandb.Image('valid_matrix.png')\n    })\n\nwandb.run.finish()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"./best_model.pth\"> Download Model</a>","metadata":{}}]}