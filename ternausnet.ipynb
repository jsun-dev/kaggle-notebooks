{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision\n!pip install matplotlib\n!pip install opencv-python\n!pip install imutils\n!pip install scikit-learn\n!pip install tqdm\n!pip install ternausnet\n!pip install gdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T13:50:13.454728Z","iopub.execute_input":"2022-04-27T13:50:13.45506Z","iopub.status.idle":"2022-04-27T13:51:53.971892Z","shell.execute_reply.started":"2022-04-27T13:50:13.454961Z","shell.execute_reply":"2022-04-27T13:51:53.970752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\n\nurl = 'https://drive.google.com/uc?id=12tPof_SUIDlxLP1N2GI0LiHoAHNlXJpt'\n\noutput = 'MIDV_2020_dataset.zip'\ngdown.download(url, output)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:51:58.049112Z","iopub.execute_input":"2022-04-27T13:51:58.049494Z","iopub.status.idle":"2022-04-27T13:52:40.075026Z","shell.execute_reply.started":"2022-04-27T13:51:58.049455Z","shell.execute_reply":"2022-04-27T13:52:40.074037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip MIDV_2020_dataset.zip >/dev/null\nprint('[INFO] The training dataset has been unzipped...')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:53:06.955318Z","iopub.execute_input":"2022-04-27T13:53:06.95574Z","iopub.status.idle":"2022-04-27T13:53:30.019282Z","shell.execute_reply.started":"2022-04-27T13:53:06.95571Z","shell.execute_reply":"2022-04-27T13:53:30.018195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir outputs","metadata":{"execution":{"iopub.status.busy":"2022-04-27T13:53:35.809784Z","iopub.execute_input":"2022-04-27T13:53:35.810108Z","iopub.status.idle":"2022-04-27T13:53:36.561856Z","shell.execute_reply.started":"2022-04-27T13:53:35.810076Z","shell.execute_reply":"2022-04-27T13:53:36.560525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary packages\nfrom torch.utils.data import Dataset\nfrom ternausnet.models import UNet11\nfrom ternausnet.models import UNet16\nfrom torch.nn import BCEWithLogitsLoss\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms\nfrom imutils import paths\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport torch\nimport time\nimport cv2\nimport os\nimport imutils","metadata":{"execution":{"iopub.status.busy":"2022-04-27T17:37:26.7503Z","iopub.execute_input":"2022-04-27T17:37:26.750914Z","iopub.status.idle":"2022-04-27T17:37:26.757598Z","shell.execute_reply.started":"2022-04-27T17:37:26.750879Z","shell.execute_reply":"2022-04-27T17:37:26.756517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Base path of the dataset\nDATASET_PATH = os.path.join('MIDV_2020_dataset', 'train')\n\n# Define the path to the images and masks dataset\nIMAGE_DATASET_PATH = os.path.join(DATASET_PATH, 'images')\nMASK_DATASET_PATH = os.path.join(DATASET_PATH, 'masks')\n\n# Define the test split\nTEST_SPLIT = 0.15\n\n# Determine the device to be used for training and evaluation\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# Determine if we will be pinning memory during data loading\nPIN_MEMORY = True if DEVICE == 'cuda' else False\n\n# Define the number of channels in the input, number of classes,\n# and number of levels in the U-Net model\nNUM_CHANNELS = 1\nNUM_CLASSES = 1\nNUM_LEVELS = 3\n\n# HYPERPARAMETERS\n# Initialize learning rate, number of epochs, and batch size\nINIT_LR = 0.001\nNUM_EPOCHS = 15\nBATCH_SIZE = 16\n\n# Define the input image dimensions\nINPUT_IMAGE_WIDTH = 256\nINPUT_IMAGE_HEIGHT = 256\n\n# Define threshold to filter weak predictions\nTHRESHOLD = 0.5\n\n# Define the path to the base output directory\nBASE_OUTPUT = 'outputs'\n\n# Define the path to the testing image paths\nTEST_PATHS = os.path.sep.join([BASE_OUTPUT, 'test_paths.txt'])","metadata":{"execution":{"iopub.status.busy":"2022-04-27T17:37:29.773229Z","iopub.execute_input":"2022-04-27T17:37:29.774684Z","iopub.status.idle":"2022-04-27T17:37:29.784502Z","shell.execute_reply.started":"2022-04-27T17:37:29.774624Z","shell.execute_reply":"2022-04-27T17:37:29.783413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SegmentationDataset(Dataset):\n    def __init__(self, imagePaths, maskPaths, transforms):\n        # Store the image and mask filepaths, and augmentation transforms\n        self.imagePaths = imagePaths\n        self.maskPaths = maskPaths\n        self.transforms = transforms\n\n    def __len__(self):\n        # Return the number of total samples contained in the dataset\n        return len(self.imagePaths)\n\n    def __getitem__(self, idx):\n        # Grab the image path from the current index\n        imagePath = self.imagePaths[idx]\n\n        # Load the image from disk, swap its channels from BGR to RGB,\n        # and read the associated mask from disk in grayscale mode\n        image = cv2.imread(imagePath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.maskPaths[idx], 0)\n\n        # Check to see if we are applying any transformations\n        if self.transforms is not None:\n            # Apply the transformations to both image and its mask\n            image = self.transforms(image)\n            mask = self.transforms(mask)\n\n        # Return the image and its mask\n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2022-04-27T17:37:33.3313Z","iopub.execute_input":"2022-04-27T17:37:33.331893Z","iopub.status.idle":"2022-04-27T17:37:33.340603Z","shell.execute_reply.started":"2022-04-27T17:37:33.331857Z","shell.execute_reply":"2022-04-27T17:37:33.33965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_model(model, epoch, H):\n    # Plot the training loss\n    plt.style.use('ggplot')\n    plt.figure()\n    plt.plot(H['train_loss'], label='train_loss')\n    plt.plot(H['test_loss'], label='test_loss')\n    plt.title('Training Loss on Dataset')\n    plt.xlabel('Epoch #')\n    plt.ylabel('Loss')\n    plt.legend(loc='lower left')\n    plt.savefig(os.path.sep.join([BASE_OUTPUT, str(epoch) + '_plot.png']))\n\n    # Serialize the model to disk\n    torch.save(model, os.path.join(BASE_OUTPUT, str(epoch) + '_unet11_midv_2020.path'))","metadata":{"execution":{"iopub.status.busy":"2022-04-27T17:37:36.670474Z","iopub.execute_input":"2022-04-27T17:37:36.671103Z","iopub.status.idle":"2022-04-27T17:37:36.678562Z","shell.execute_reply.started":"2022-04-27T17:37:36.671066Z","shell.execute_reply":"2022-04-27T17:37:36.677566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the image and mask filepaths in a sorted manner\nimagePaths = sorted(list(paths.list_images(IMAGE_DATASET_PATH)))\nmaskPaths = sorted(list(paths.list_images(MASK_DATASET_PATH)))\n\n# Partition the data into training and testing splits using 85% of\n# the data for training and the remaining 15% for testing\nsplit = train_test_split(imagePaths, maskPaths, test_size=TEST_SPLIT, random_state=42)\n\n# Unpack the data split\ntrainImages, testImages = split[:2]\ntrainMasks, testMasks = split[2:]\n\n# Write the testing image paths to disk so that we can use them\n# when evaluating/testing our model\nprint(\"[INFO] Saving testing image paths...\")\nf = open(TEST_PATHS, 'w')\nf.write('\\n'.join(testImages))\nf.close()\n\n# Define transformations\ntransforms = transforms.Compose([transforms.ToPILImage(),\n                                 transforms.Resize((INPUT_IMAGE_HEIGHT,\n                                                    INPUT_IMAGE_WIDTH)),\n                                 transforms.ToTensor()])\n\n# Create the train and test datasets\ntrainDS = SegmentationDataset(imagePaths=trainImages, maskPaths=trainMasks, transforms=transforms)\ntestDS = SegmentationDataset(imagePaths=testImages, maskPaths=testMasks, transforms=transforms)\nprint(f\"[INFO] Found {len(trainDS)} examples in the training set...\")\nprint(f\"[INFO] Found {len(testDS)} examples in the test set...\")\n\n# Create the training and test data loaders\ntrainLoader = DataLoader(trainDS, shuffle=True,\n                         batch_size=BATCH_SIZE, pin_memory=PIN_MEMORY,\n                         num_workers=os.cpu_count())\ntestLoader = DataLoader(testDS, shuffle=False,\n                        batch_size=BATCH_SIZE, pin_memory=PIN_MEMORY,\n                        num_workers=os.cpu_count())\n\n# Initialize the U-Net11 model with pre-trained VGG11 encoders\nunet = UNet11(pretrained=True).to(DEVICE)\n\n# Initialize the U-Net16 model with pre-trained VGG16 encoders\n# unet = UNet16(pretrained=True).to(DEVICE)\n\n# Initialize the loss function and optimizer\nlossFunc = BCEWithLogitsLoss()\nopt = Adam(unet.parameters(), lr=INIT_LR)\n\n# Calculate steps per epoch for training and test set\ntrainSteps = len(trainDS) // BATCH_SIZE\ntestSteps = len(testDS) // BATCH_SIZE\n\n# Initialize a dictionary to store training history\nH = {'train_loss': [], 'test_loss': []}\n\n# Define the current best test loss\nbestTestLoss = 0.015\n\n# Loop over epochs\nprint(\"[INFO] Training the network...\")\nstartTime = time.time()\nfor e in tqdm(range(NUM_EPOCHS)):\n    # Set the model in training mode\n    unet.train()\n    \n    # Initialize the total training and validation loss\n    totalTrainLoss = 0\n    totalTestLoss = 0\n\n    # Loop over the training set\n    for (i, (x, y)) in enumerate(trainLoader):\n        print('Epoch ', e + 1, ': ', i + 1, '/', len(trainLoader), sep='')\n        # Send the input to the device\n        (x, y) = (x.to(DEVICE), y.to(DEVICE))\n\n        # Perform a forward pass and calculate the training loss\n        pred = unet(x)\n        loss = lossFunc(pred, y)\n\n        # First, zero out any previously accumulated gradients, then\n        # perform backpropagation, and then update model parameters\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n\n        # Add the loss to the total training loss so far\n        totalTrainLoss += loss\n\n    # Switch off autograd\n    with torch.no_grad():\n        # Set the model in evaluation mode\n        unet.eval()\n\n        # Loop over the validation set\n        for (x, y) in testLoader:\n            # Send the input to the device\n            (x, y) = (x.to(DEVICE), y.to(DEVICE))\n\n            # Make the predictions and calculate the validation loss\n            pred = unet(x)\n            totalTestLoss += lossFunc(pred, y)\n\n        # Calculate the average training and validation loss\n        avgTrainLoss = totalTrainLoss / trainSteps\n        avgTestLoss = totalTestLoss / testSteps\n\n        # Update our training history\n        H['train_loss'].append(avgTrainLoss.cpu().detach().numpy())\n        H['test_loss'].append(avgTestLoss.cpu().detach().numpy())\n\n        # Print the model training and validation information\n        print(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n        print(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(avgTrainLoss, avgTestLoss))\n    \n        # Save the current model if the test loss is better\n        if avgTestLoss < bestTestLoss:\n            print('[INFO] Test loss has improved, saving current model...')\n            bestTestLoss = avgTestLoss\n            save_model(unet, e + 1, H)\n\n# Display the total time needed to perform the training\nendTime = time.time()\nprint(\"[INFO] Total time taken to train the model: {:.2f}s\".format(endTime - startTime))\n\n# Save the final model\nsave_model(unet, -1, H)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T17:37:39.238533Z","iopub.execute_input":"2022-04-27T17:37:39.238839Z","iopub.status.idle":"2022-04-27T18:35:05.610865Z","shell.execute_reply.started":"2022-04-27T17:37:39.238806Z","shell.execute_reply":"2022-04-27T18:35:05.609882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Clear output directory\noutputPath = '/kaggle/working/outputs'\nfiles = os.listdir(outputPath)\n\nfor f in files:\n    os.remove(outputPath + '/' + f)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T17:37:03.415957Z","iopub.execute_input":"2022-04-27T17:37:03.416298Z","iopub.status.idle":"2022-04-27T17:37:03.512722Z","shell.execute_reply.started":"2022-04-27T17:37:03.416245Z","shell.execute_reply":"2022-04-27T17:37:03.511634Z"},"trusted":true},"execution_count":null,"outputs":[]}]}